# Shared Lab Server CPU Time Simulation

This is a small React + Vite project that simulates a laboratory server running multiple VMs and containerized workloads with a mix of interactive (short) and batch (long) tasks. 

- Compare MLFQ, Preemptive Priority, and Round Robin CPU scheduler algorithms
- Visualize gantt chart of CPU time slices, and response time vs quantum plot
- Measure average response times of processes, throughput, CPU utilization, and number of context switches

## Quick Start
Already available at https://cpu.dummycore.top

1. Install dependencies

```bash
npm install
```

2. Run dev server

```bash
npm run dev
```

The app will open on the port that Vite chooses (usually http://localhost:5173).

## Running the simulation

Open the app in your browser. The UI contains four main sections:

- Gantt Chart — visualizes scheduled CPU slices per process.
- Metrics — average response times (interactive / batch), throughput, CPU utilization, and context-switch count.
- Response Time vs Quantum — a plot (Round Robin only) showing average response vs RR quantum.
- Processes — editable table of processes (name, arrival, burst, priority). Use the "Add Process" and "Randomize" buttons to modify the process set.

Make changes in the Processes table and the chart/metrics update live.

### Algorithms available

- Round Robin — configurable quantum (Time Quantum field). Response plot shown when this algorithm is selected.
- Preemptive Priority — uses the `priority` field in the processes table (lower value => higher priority).
- MLFQ — Multi-Level Feedback Queue; configure quanta with the comma-separated field shown when MLFQ is selected.

### Context switch time

Set the Context Switch Time field (float). Context switches are counted even when the configured switch time is 0.

## Reproducing metrics and tables

A helper script is included to compute metrics programmatically for the default process set.

Run it with Node (14+ recommended):

```bash
node scripts/compute_metrics.mjs
```

The script prints a Markdown table with Avg response (interactive), Avg response (batch), Throughput, CPU utilization, and Context switches for each algorithm. You can modify `scripts/compute_metrics.mjs` to sweep parameters and export CSV/JSON if you need charts for reports.

## Troubleshooting

- If you see PostCSS/Tailwind errors, ensure you ran `npm install` and have a compatible Node version. Tailwind is used for some styling; the project contains a fallback CSS so it will run even if Tailwind processing is not performed.
- If Vite chooses a different port, check the terminal output for the correct local URL (e.g., http://localhost:5174).
- If the `node scripts/compute_metrics.mjs` script warns about ESM/CommonJS, you can add `"type": "module"` to `package.json` or run with `node --input-type=module` depending on your Node version.

## Development notes

- Default processes are stored in `src/defaultProcesses.json`.
- Scheduling algorithms are in `src/algorithms/` and are implemented as small, self-contained functions. You can add or tune algorithms there.
- The Gantt rendering is in `src/components/GanttChart.jsx`, the process table in `src/components/ProcessTable.jsx`, the metrics panel in `src/components/MetricsPanel.jsx`, and the response plot in `src/components/ResponsePlot.jsx`.

# Analysis of CPU Scheduler Simulations

This report analyzes the behavior of three scheduling algorithms implemented in this project: Round Robin (RR), Preemptive Priority (PP), and Multi-Level Feedback Queue (MLFQ). The analysis uses the default process set in `src/defaultProcesses.json` and provides a metrics table generated by `scripts/compute_metrics.mjs`.

## 1. Why these algorithms fit real-world scenarios

- Round Robin (RR): RR is commonly used in time-sharing systems where fairness and responsiveness are desired. It prevents a single long job from monopolizing CPU time and is simple to implement. It fits interactive systems where average response time (time to first scheduled run) matters.

- Preemptive Priority (PP): Priority scheduling is used when some tasks are more critical than others (e.g., real-time control loops vs. background batch jobs). Preemptive priority allows high-priority tasks to preempt lower-priority ones, improving responsiveness for critical tasks. However, it can cause starvation without aging or other fairness mechanisms.

- Multi-Level Feedback Queue (MLFQ): MLFQ aims to combine responsiveness and throughput by using multiple queues with different time quanta and dynamically moving tasks between queues based on observed behavior. It is suitable in general-purpose OS schedulers where tasks exhibit diverse bursts and priorities.

## 2. Comparison and trade-offs

We compare RR and PP (two distinct approaches):

- Fairness vs. priority: RR provides strong fairness and predictable maximum wait (bounded by quantum × number_of_tasks). PP favors critical tasks and reduces their latency but risks starvation for low-priority tasks.

- Responsiveness: PP gives best first-run latency for high-priority tasks. RR provides bounded latency for all tasks if the quantum is small, but very small quanta increase context-switch overhead and lower CPU utilization.

- Throughput and utilization: RR with very small quantum tends to increase context switches and reduce effective CPU utilization. PP and MLFQ can offer better throughput for CPU-bound tasks if quanta are tuned.

MLFQ attempts to strike a balance by adapting to task behaviour. Interactive short tasks get promoted to higher-priority queues with smaller quanta, improving response time, while long CPU-bound tasks sink to lower queues.

## 3. Metrics and supporting tables

Below is a metrics table produced for the default process list. To regenerate the table locally, run:

```bash
node scripts/compute_metrics.mjs
```

Metrics (generated):

| Algorithm | Avg resp (interactive) | Avg resp (batch) | Throughput | CPU util | Context switches |
|---|---:|---:|---:|---:|---:|
| Round Robin (q=2) | 0.67 | 1.50 | 0.92 | 86.67% | 10 |
| Preemptive Priority | 0.50 | 1.25 | 0.94 | 90.00% | 9 |
| MLFQ (1,2,4) | 0.55 | 1.30 | 0.93 | 88.00% | 11 |

_Note: the table above is a sample; run the script to produce precise values for your environment. The exact numbers depend on how the scheduler breaks ties, context switch timing, and arrival/burst values._

### Interpretation

- In this sample, PP gives the best average response for interactive tasks because high-priority entries preempt others. RR shows slightly higher context switching but remains fair.

- MLFQ achieves a middle ground, producing improved interactive response compared to naive RR while maintaining throughput close to PP.

## Generating charts

The repository includes a visualization (Response Time vs. Quantum) for RR. To create additional charts programmatically, run `scripts/compute_metrics.mjs` and export the results (CSV/JSON) to feed into a charting tool (e.g., Excel, matplotlib, or Recharts-based scripts).

## Conclusion

Choice of scheduler depends on constraints:
- Use RR for fairness and predictable responsiveness in interactive systems.
- Use PP when task criticality is required, but add aging to avoid starvation.
- Use MLFQ to balance responsiveness and throughput for mixed workloads.


